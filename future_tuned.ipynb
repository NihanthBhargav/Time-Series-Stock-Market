{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d5ff9b3",
   "metadata": {},
   "source": [
    "## Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4609dbca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaned. Shape: (2515, 1)\n",
      "                Close\n",
      "Date                 \n",
      "2015-01-02  24.288584\n",
      "2015-01-05  23.604326\n",
      "2015-01-06  23.606552\n",
      "2015-01-07  23.937569\n",
      "2015-01-08  24.857311\n",
      "Best ARIMA params: (0, 1, 0) | AIC: 10434.071740645499\n",
      "Best SARIMA params: ((0, 1, 0), (0, 0, 0, 12)) | AIC: 10434.071740645499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21:44:49 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:44:50 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prophet model trained.\n",
      "LSTM model trained.\n",
      "\n",
      " All models completed! Forecasts saved in 'Models/' folder.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import itertools\n",
    "import os\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from prophet import Prophet\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.makedirs(\"Models\", exist_ok=True)\n",
    "\n",
    "# ===================== DATA CLEANING =====================\n",
    "df = pd.read_csv(\"AAPL_clean.csv\", parse_dates=['Date'])\n",
    "df = df[['Date', 'Close']]\n",
    "\n",
    "df['Close'] = pd.to_numeric(df['Close'], errors='coerce')\n",
    "df = df.dropna(subset=['Close'])\n",
    "df.set_index('Date', inplace=True)\n",
    "\n",
    "print(\"Data cleaned. Shape:\", df.shape)\n",
    "print(df.head())\n",
    "\n",
    "# ===================== ARIMA TUNING =====================\n",
    "p = d = q = range(0, 3)\n",
    "pdq = list(itertools.product(p, d, q))\n",
    "\n",
    "best_aic, best_params, best_model = np.inf, None, None\n",
    "for param in pdq:\n",
    "    try:\n",
    "        model = ARIMA(df['Close'], order=param)\n",
    "        results = model.fit()\n",
    "        if results.aic < best_aic:\n",
    "            best_aic, best_params, best_model = results.aic, param, results\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "if best_model:\n",
    "    print(\"Best ARIMA params:\", best_params, \"| AIC:\", best_aic)\n",
    "    forecast = best_model.forecast(steps=30)\n",
    "    arima_df = pd.DataFrame({\n",
    "        'Date': pd.date_range(start=df.index[-1] + pd.offsets.BDay(1), periods=30, freq='B'),\n",
    "        'Forecast': forecast\n",
    "    })\n",
    "    arima_df.to_csv(\"Models/future_arima.csv\", index=False)\n",
    "else:\n",
    "    print(\"ARIMA failed.\")\n",
    "\n",
    "# ===================== SARIMA TUNING =====================\n",
    "pdq = list(itertools.product(range(0, 2), repeat=3))\n",
    "seasonal_pdq = [(x[0], x[1], x[2], 12) for x in pdq]\n",
    "\n",
    "best_aic, best_params, best_model = np.inf, None, None\n",
    "for param in pdq:\n",
    "    for param_seasonal in seasonal_pdq:\n",
    "        try:\n",
    "            model = SARIMAX(df['Close'], order=param, seasonal_order=param_seasonal)\n",
    "            results = model.fit(disp=False)\n",
    "            if results.aic < best_aic:\n",
    "                best_aic, best_params, best_model = results.aic, (param, param_seasonal), results\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "if best_model:\n",
    "    print(\"Best SARIMA params:\", best_params, \"| AIC:\", best_aic)\n",
    "    forecast = best_model.forecast(steps=30)\n",
    "    sarima_df = pd.DataFrame({\n",
    "        'Date': pd.date_range(start=df.index[-1] + pd.offsets.BDay(1), periods=30, freq='B'),\n",
    "        'Forecast': forecast\n",
    "    })\n",
    "    sarima_df.to_csv(\"Models/future_sarima.csv\", index=False)\n",
    "else:\n",
    "    print(\"SARIMA failed.\")\n",
    "\n",
    "# ===================== PROPHET =====================\n",
    "prophet_df = df.reset_index().rename(columns={\"Date\": \"ds\", \"Close\": \"y\"})\n",
    "prophet_model = Prophet(daily_seasonality=True)\n",
    "prophet_model.fit(prophet_df)\n",
    "\n",
    "future = prophet_model.make_future_dataframe(periods=30)\n",
    "forecast = prophet_model.predict(future)\n",
    "\n",
    "prophet_df_out = forecast[['ds', 'yhat']].tail(30).rename(columns={'ds': 'Date', 'yhat': 'Forecast'})\n",
    "prophet_df_out.to_csv(\"Models/future_prophet.csv\", index=False)\n",
    "print(\"Prophet model trained.\")\n",
    "\n",
    "# ===================== LSTM =====================\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(df[['Close']])\n",
    "\n",
    "X, y = [], []\n",
    "for i in range(60, len(scaled_data)):\n",
    "    X.append(scaled_data[i-60:i, 0])\n",
    "    y.append(scaled_data[i, 0])\n",
    "\n",
    "X, y = np.array(X), np.array(y)\n",
    "X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, return_sequences=True, input_shape=(X.shape[1], 1)))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model.fit(X, y, epochs=5, batch_size=32, verbose=0)\n",
    "\n",
    "last_60 = scaled_data[-60:]\n",
    "future_preds = []\n",
    "curr_batch = last_60.reshape((1, 60, 1))\n",
    "\n",
    "for _ in range(30):  \n",
    "    pred = model.predict(curr_batch, verbose=0)[0][0]\n",
    "    future_preds.append(pred)\n",
    "    \n",
    "    pred_reshaped = np.array(pred).reshape(1, 1, 1)\n",
    "    \n",
    "    curr_batch = np.concatenate([curr_batch[:, 1:, :], pred_reshaped], axis=1)\n",
    "\n",
    "future_preds = scaler.inverse_transform(np.array(future_preds).reshape(-1, 1))\n",
    "\n",
    "lstm_df = pd.DataFrame({\n",
    "    'Date': pd.date_range(start=df.index[-1] + pd.offsets.BDay(1), periods=30, freq='B'),\n",
    "    'Forecast': future_preds.flatten()\n",
    "})\n",
    "lstm_df.to_csv(\"Models/future_lstm.csv\", index=False)\n",
    "print(\"LSTM model trained.\")\n",
    "\n",
    "print(\"\\n All models completed! Forecasts saved in 'Models/' folder.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
